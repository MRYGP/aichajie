# 三湘问道 - AI产品研究智能体工作流完整设计

**版本**: v1.0  
**日期**: 2026-01-08  
**目标**: 设计可落地的3智能体系统，实现"研究AI产品→积累案例→多渠道输出"的完整闭环

---

## 一、系统架构总览

### 1.1 三智能体系统

```
┌─────────────────────────────────────────────────────────┐
│                    输入: AI产品名称                        │
│                   (Perplexity, Cursor...)                │
└────────────────────┬────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────┐
│  智能体1: 信息收集器 (Info Collector)                      │
│  - 工具: Perplexity API + Web Scraper                    │
│  - 输出: intake_card.md (30分钟)                          │
│  - 存储: signals/watchlist.md                            │
└────────────────────┬────────────────────────────────────┘
                     ↓
                人工审核 (20%精力)
                补充关键信息
                     ↓
┌─────────────────────────────────────────────────────────┐
│  智能体2: 深度分析师 (Deep Analyzer)                       │
│  - 工具: Claude + Project Knowledge                      │
│  - 输出: app_case_file.md (2小时)                         │
│  - 存储: cases/2026/xxx.md                               │
└────────────────────┬────────────────────────────────────┘
                     ↓
                人工编辑 (50%精力)
                添加个人洞察
                     ↓
┌─────────────────────────────────────────────────────────┐
│  智能体3: 内容改写师 (Content Rewriter)                    │
│  - 工具: Claude + Prompt Templates                       │
│  - 输出1: 公众号文章 (1小时)                               │
│  - 输出2: 短视频脚本 (30分钟)                              │
│  - 存储: articles/ + scripts/                            │
└────────────────────┬────────────────────────────────────┘
                     ↓
                人工润色 (30%精力)
                     ↓
┌─────────────────────────────────────────────────────────┐
│              多渠道发布                                    │
│  - 公众号 (早上9点)                                       │
│  - 抖音/小红书 (晚上8点)                                  │
│  - 知乎/即刻 (随时)                                       │
└─────────────────────────────────────────────────────────┘
```

### 1.2 数据流转

```
AI产品名称
    ↓
signals/watchlist.md (登记卡)
    ↓
cases/2026/xxx.md (深度分析)
    ↓
├→ articles/2026/xxx-深度拆解.md (公众号)
├→ scripts/2026/xxx-60s.md (短视频)
└→ 三湘问道评估系统 (反哺)
```

---

## 二、智能体1: 信息收集器 (Info Collector)

### 2.1 核心功能

**目标**: 快速收集AI产品的基础信息，生成标准化登记卡

**时间**: 30分钟/个产品

### 2.2 工作流程

```
Step 1: 输入产品名称
    ↓
Step 2: 多源信息收集
    ├→ 官网爬取 (产品介绍/定价)
    ├→ Crunchbase (融资/团队)
    ├→ ProductHunt (用户评价)
    ├→ Twitter (创始人动态)
    └→ 技术博客 (技术栈)
    ↓
Step 3: 信息整合
    ↓
Step 4: 生成登记卡 (intake_card.md)
    ↓
Step 5: 保存到 signals/watchlist.md
```

### 2.3 工具选型

#### 工具组合 (推荐方案)

**方案A: Perplexity API + Manual Review** (推荐)

```python
# 伪代码
import perplexity_api

def collect_info(product_name):
    # Step 1: 用Perplexity搜索基础信息
    query = f"""
    请收集{product_name}的以下信息:
    1. 官网和产品介绍
    2. 创始团队背景
    3. 融资情况 (轮次/金额/投资方)
    4. 技术栈
    5. 用户规模 (如果有公开数据)
    6. 核心痛点
    """
    
    result = perplexity_api.search(query)
    
    # Step 2: 结构化输出
    info_card = {
        "name": product_name,
        "website": result.extract("官网"),
        "founders": result.extract("创始人"),
        "funding": result.extract("融资"),
        "tech_stack": result.extract("技术栈"),
        "pain_points": result.extract("痛点"),
        "sources": result.citations
    }
    
    # Step 3: 生成Markdown
    markdown = generate_intake_card(info_card)
    
    # Step 4: 保存
    save_to_watchlist(markdown)
    
    return info_card
```

**关键工具**:
- Perplexity Pro ($20/月) - 用于信息搜索
- Python + Perplexity API - 自动化收集
- 或者: 手动用Perplexity搜索 + 复制到模板

#### 工具组合 (备选方案)

**方案B: Claude + Web Browser Extension**

- 用浏览器插件 (如Bardeen) 抓取官网信息
- 复制到Claude，用Prompt生成登记卡
- 手动补充融资/团队信息 (Crunchbase)

**方案C: 全自动爬虫** (技术门槛高)

- Scrapy + Selenium 爬取官网
- Crunchbase API 获取融资信息
- 集成到一个自动化脚本

**推荐**: 前期用方案A (Perplexity API)，100个案例后考虑方案C

### 2.4 输出模板

**templates/intake_card.md**:

```markdown
---
name: ""
website: ""
sector: ""
status: "待研究"
priority: ""  # P0/P1/P2
first_seen: "YYYY-MM-DD"
research_deadline: ""  # 建议研究截止日期
---

## 基础信息

### 官方信息
- **官网**: 
- **产品简介**: (一句话)
- **标语/Slogan**: 

### 创始团队
- **创始人**: 
- **背景**: (简要，如: 前Google工程师)
- **团队规模**: 

### 融资情况
- **融资轮次**: 
- **融资金额**: 
- **投资方**: 
- **估值**: (如果有)
- **来源**: (Crunchbase链接)

### 技术信息
- **技术栈**: (如: React + Python + OpenAI API)
- **核心技术**: (如: RAG, Fine-tuning)
- **依赖**: (是否依赖第三方API)

## 初步分析

### 目标用户 (初步判断)
- 

### 核心痛点 (初步判断)
- 

### 市场机会 (初步判断)
- 评分: ?/10
- 理由: 

### 技术壁垒 (初步判断)
- 评分: ?/10
- 理由: 

### 竞争风险 (初步判断)
- 评分: ?/10
- 理由: 

## 信息来源

| 信息 | 来源 | 链接 | 可信度 |
|------|------|------|--------|
| 融资信息 | Crunchbase | https://... | A |
| 产品介绍 | 官网 | https://... | A |
| 用户评价 | ProductHunt | https://... | B |

## 下一步行动

- [ ] 深度研究 (预计2小时)
- [ ] 晋级到cases/
- [ ] 或继续观察 (设置提醒: YYYY-MM-DD)

## 标签
#AI搜索 #RAG #B轮 #优先研究
```

### 2.5 自动化脚本 (Python)

**scripts/agent1_collector.py**:

```python
#!/usr/bin/env python3
"""
智能体1: 信息收集器
使用Perplexity API自动收集AI产品信息
"""

import os
from datetime import datetime
from perplexity import PerplexityAPI  # 假设有这个库

class InfoCollector:
    def __init__(self, api_key):
        self.pplx = PerplexityAPI(api_key)
        self.template_path = "templates/intake_card.md"
        self.output_path = "signals/watchlist.md"
    
    def collect(self, product_name):
        """收集单个产品信息"""
        print(f"开始收集: {product_name}")
        
        # 构建查询
        query = self._build_query(product_name)
        
        # 调用Perplexity API
        result = self.pplx.search(query)
        
        # 解析结果
        info = self._parse_result(result)
        
        # 生成Markdown
        markdown = self._generate_markdown(info)
        
        # 保存
        self._save_to_watchlist(markdown)
        
        print(f"完成收集: {product_name}")
        return info
    
    def _build_query(self, product_name):
        """构建Perplexity查询"""
        return f"""
        请收集{product_name}的以下信息:
        1. 官网URL
        2. 产品一句话介绍
        3. 创始人姓名和背景
        4. 最新融资情况 (轮次/金额/投资方/日期)
        5. 技术栈 (编程语言/框架/使用的AI模型)
        6. 用户规模 (MAU/付费用户数，如果有公开数据)
        7. 定价模式
        
        要求:
        - 每条信息必须标注来源
        - 没有可靠数据就写"unknown"
        - 融资信息优先用Crunchbase
        """
    
    def _parse_result(self, result):
        """解析Perplexity返回结果"""
        # 实际实现需要根据API返回格式调整
        info = {
            "name": result.get("product_name"),
            "website": result.get("website"),
            "intro": result.get("intro"),
            "founders": result.get("founders"),
            "funding": result.get("funding"),
            "tech_stack": result.get("tech_stack"),
            "users": result.get("users", "unknown"),
            "pricing": result.get("pricing"),
            "sources": result.get("citations", [])
        }
        return info
    
    def _generate_markdown(self, info):
        """生成Markdown格式的登记卡"""
        # 读取模板
        with open(self.template_path, 'r') as f:
            template = f.read()
        
        # 填充数据
        markdown = template.format(
            name=info['name'],
            website=info['website'],
            intro=info['intro'],
            founders=info['founders'],
            funding=info['funding'],
            tech_stack=info['tech_stack'],
            date=datetime.now().strftime("%Y-%m-%d"),
            # ... 其他字段
        )
        
        return markdown
    
    def _save_to_watchlist(self, markdown):
        """保存到watchlist"""
        with open(self.output_path, 'a') as f:
            f.write("\n---\n\n")
            f.write(markdown)
    
    def batch_collect(self, product_list):
        """批量收集"""
        results = []
        for product in product_list:
            info = self.collect(product)
            results.append(info)
        return results

# 使用示例
if __name__ == "__main__":
    api_key = os.getenv("PERPLEXITY_API_KEY")
    collector = InfoCollector(api_key)
    
    # 单个收集
    collector.collect("Perplexity")
    
    # 批量收集
    products = ["Perplexity", "Cursor", "Claude", "Midjourney"]
    collector.batch_collect(products)
```

### 2.6 人工审核清单

**每个登记卡必须人工检查**:

- [ ] 融资信息是否有来源链接?
- [ ] 创始人背景是否准确?
- [ ] 技术栈是否合理? (不要被营销话术误导)
- [ ] 是否标注了"unknown"而非瞎编数据?
- [ ] 优先级标注是否合理? (P0=必须研究, P1=有价值, P2=观察)

**审核时间**: 5-10分钟/个

---

## 三、智能体2: 深度分析师 (Deep Analyzer)

### 3.1 核心功能

**目标**: 深度研究AI产品，生成完整的案例分析文件

**时间**: 2小时/个产品 (前期), 1小时/个 (熟练后)

### 3.2 工作流程

```
Step 1: 读取登记卡 (signals/watchlist.md)
    ↓
Step 2: 深度研究 (7个维度)
    ├→ 使用产品 (实际体验30分钟)
    ├→ 阅读技术博客/文档
    ├→ 查看用户评价 (Twitter/Reddit/ProductHunt)
    ├→ 对标分析 (找2-3个类似产品)
    └→ 理论映射 (从knowledge-base/搜索相关理论)
    ↓
Step 3: Claude辅助分析
    ├→ 用Project Knowledge (三湘问道知识库)
    ├→ 按照app_case_file.md模板生成初稿
    └→ 自动填充证据账本
    ↓
Step 4: 人工深度编辑 (核心!)
    ├→ 补充个人洞察
    ├→ 添加"没有男朋友的女孩子"分析
    ├→ 提炼成功/失败机制
    └→ 检查证据账本
    ↓
Step 5: 生成最终版 (cases/2026/xxx.md)
```

### 3.3 工具选型

#### 主要工具

**1. Claude Projects (核心)**
- 用途: 深度分析，利用三湘问道知识库
- 优势: 44万字知识库已上传，理论映射自动化
- 价格: Claude Pro $20/月

**2. Notion/Obsidian (笔记)**
- 用途: 边研究边记录
- 推荐: Notion (协作方便)

**3. Screen录屏工具**
- 用途: 录制产品使用过程 (后面做视频)
- 推荐: OBS Studio (免费) / ScreenFlow (Mac)

#### 辅助工具

**4. ProductHunt / Reddit**
- 用途: 查看真实用户评价
- 关键: 看1星评价 (痛点在哪)

**5. SimilarWeb / Ahrefs**
- 用途: 查看流量数据
- 注意: 数据可能不准，标注为C级证据

### 3.4 Claude Prompt模板

**在Claude Projects中创建自定义Prompt**:

```markdown
# 智能体2: 深度分析师 Prompt

你是AI产品深度分析专家，负责按照app_case_file.md模板生成完整的案例分析。

## 输入
我会提供：
1. 产品名称
2. 登记卡信息 (基础信息)
3. 我的实际使用体验笔记

## 你的任务

### Step 1: 补充信息收集
基于登记卡，列出还需要收集的信息清单：
- 缺少哪些关键信息?
- 建议从哪里获取?

### Step 2: 7个维度深度分析

严格按照以下模板输出：

#### 1) 一句话结论
- 这个产品本质上是在替代谁的什么工作?
- 用"替代函数"的思维: 原来的方式 → 新的方式

#### 2) 用户与场景 (Job to be Done)
- **目标用户**: (具体画像，不要泛泛而谈)
- **高频/低频、刚需/可选**: (判断并说明理由)
- **工作流嵌入点**: (在用户工作流的哪个环节切入?)
- **真实痛点**: (是真痛点还是伪需求? 有什么证据?)

#### 3) 产品与价值
- **核心功能**: (列出1-3个核心功能)
- **交付物是否可直接使用**: (vs 只是提供建议)
- **为什么用户会持续用**: (留存机制)
- **"啊哈时刻"**: (用户第一次用就"哇"的那个瞬间)

#### 4) 商业化与单位经济
- **付费方**: (谁付钱? B端/C端/平台抽成?)
- **定价方式**: (订阅/按次/按结果/混合)
- **ROI公式**: (用一句话说清楚用户的投资回报)
- **成本结构风险**: (推理成本/人工审核/集成成本)
- **LTV/CAC**: (如果有数据就计算，没有就标unknown)

#### 5) 增长与分发机制
- **获客渠道**: (用户从哪里来?)
- **分发楔子**: (为什么用户愿意"先试一口"?)
- **留存机制**: (为什么用户不流失?)
- **网络效应**: (用户越多，产品越好吗?)

#### 6) 护城河判断
- **数据飞轮**: 输入→行动→反馈→更好结果 (是否成立?)
- **切换成本来源**: (用户为什么不会换?)
- **技术壁垒**: (竞品需要多久复制?)
- **平台依赖风险**: (依赖第三方API的风险)

#### 7) 成功/失败机制 (最重要!)

**如果是成功案例**:
- **成功机制** (3条，用标签如success:xxx):
  1. 
  2. 
  3. 
- **最可复制的一条打法**: (哪一条别人最容易学?)

**对标分析** (必须):
- 对标对象1: 
  * 成功机制: 
  * 本产品学到什么: 
  * 差异化在哪里: 

**边缘用户策略** ("没有男朋友的女孩子"):
- 主流市场的"男朋友"是谁?
- 为什么选这个边缘用户切入?
- 如何从边缘包围主流?

### Step 3: 证据账本

列出所有关键断言的证据：

| 断言 | 来源 | 链接/出处 | 证据等级 | 可信度 | 日期 | 备注 |
|------|------|----------|---------|--------|------|------|
| ARR $10M | TechCrunch | https://... | B | 中 | 2025-01 | 未审计 |

### Step 4: 可迁移的启发

- 对应到评估框架: 用户/产品/壁垒/商业/团队 哪一项最关键?
- 可复用的验证实验(MVT): 如果要验证这个方向，90天内最小实验是什么?
- 对标学习要点: 学什么? 不学什么?

## 输出要求

1. **严格按照模板输出**
2. **每个判断必须有依据** (不要主观臆断)
3. **没有数据就标unknown** (不要瞎编)
4. **证据账本必须完整** (每条断言都要有来源)
5. **添加YAML头** (方便后续索引)

## 禁止

- ❌ 主观判断没有依据
- ❌ 编造数据 (ARR/用户数/融资额)
- ❌ 空洞的分析 ("产品很好""团队很强")
- ❌ 忽略失败风险 (必须列出失败模式预警)

## 记住

你的分析将成为"三湘问道案例库"的一部分，质量直接影响后续的项目评估质量。
```

### 3.5 人工编辑清单

**深度编辑环节 (最重要!)**:

**必须做**:
- [ ] **实际使用产品** (至少30分钟，记录使用体验)
- [ ] **添加个人洞察** (Claude不会有的观点)
- [ ] **补充"边缘用户"分析** (这需要深度思考)
- [ ] **对标分析** (至少2个成功对标，如果是失败案例则对标同类失败)
- [ ] **检查证据账本** (每条数据都有来源链接)
- [ ] **失败模式预警** (如果发现风险，标注FM编号)

**可选做**:
- [ ] 截图关键功能 (后续做文章/视频用)
- [ ] 记录"啊哈时刻" (用于短视频脚本)
- [ ] 对比竞品 (找差异点)

**时间分配**:
- Claude生成初稿: 30分钟
- 人工深度编辑: 1-1.5小时
- 总计: 2小时

### 3.6 自动化辅助脚本

**scripts/agent2_analyzer.py**:

```python
#!/usr/bin/env python3
"""
智能体2: 深度分析师
辅助脚本 - 读取登记卡，调用Claude生成分析初稿
"""

import os
from anthropic import Anthropic

class DeepAnalyzer:
    def __init__(self, api_key):
        self.client = Anthropic(api_key=api_key)
        self.template_path = "templates/app_case_file.md"
        self.output_dir = "cases/2026/"
        
        # 加载自定义Prompt
        with open("prompts/agent2_prompt.md", 'r') as f:
            self.system_prompt = f.read()
    
    def analyze(self, product_name, intake_card, user_notes=""):
        """
        深度分析单个产品
        
        Args:
            product_name: 产品名称
            intake_card: 登记卡内容
            user_notes: 用户的实际体验笔记
        """
        print(f"开始分析: {product_name}")
        
        # 构建输入
        user_message = f"""
        # 产品名称
        {product_name}
        
        # 登记卡信息
        {intake_card}
        
        # 我的使用体验笔记
        {user_notes if user_notes else "暂无"}
        
        请按照系统提示词中的模板，生成完整的深度分析。
        """
        
        # 调用Claude API
        response = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=8000,
            system=self.system_prompt,
            messages=[
                {"role": "user", "content": user_message}
            ]
        )
        
        analysis = response.content[0].text
        
        # 保存初稿
        output_path = f"{self.output_dir}{product_name.lower()}.md"
        with open(output_path, 'w') as f:
            f.write(analysis)
        
        print(f"初稿已生成: {output_path}")
        print("请进行人工深度编辑!")
        
        return analysis

# 使用示例
if __name__ == "__main__":
    api_key = os.getenv("ANTHROPIC_API_KEY")
    analyzer = DeepAnalyzer(api_key)
    
    # 读取登记卡
    with open("signals/watchlist.md", 'r') as f:
        intake_card = f.read()  # 实际使用时需要解析出特定产品
    
    # 用户笔记 (实际使用体验)
    user_notes = """
    我用了30分钟Perplexity，发现：
    1. 搜索速度很快 (5秒内返回答案)
    2. 引用质量高 (都是权威来源)
    3. 但是中文支持一般 (英文更好)
    4. "啊哈时刻": 第一次搜索就直接给出答案+3个来源，不用点10个链接
    """
    
    # 生成分析
    analyzer.analyze("Perplexity", intake_card, user_notes)
```

---

## 四、智能体3: 内容改写师 (Content Rewriter)

### 4.1 核心功能

**目标**: 将深度分析改写成多种内容形式

**输出**:
1. 公众号深度文章 (3000-5000字)
2. 短视频脚本 (60秒/3分钟)
3. 知乎问答
4. 小红书图文

**时间**: 1.5小时 (文章1小时 + 脚本30分钟)

### 4.2 工作流程

```
输入: cases/2026/perplexity.md (深度分析)
    ↓
Step 1: 提炼核心洞察 (3-5个金句)
    ↓
Step 2: 改写成公众号文章
    ├→ Claude生成初稿 (70%完成度)
    └→ 人工润色 (30%精力)
    ↓
Step 3: 改写成短视频脚本
    ├→ 60秒版本 (1个核心洞察)
    └→ 3分钟版本 (3个核心洞察)
    ↓
Step 4: 保存
    ├→ articles/2026/perplexity-深度拆解.md
    └→ scripts/2026/perplexity-60s.md
```

### 4.3 工具选型

**1. Claude API (核心)**
- 用途: 内容改写
- Prompt模板: 见下文

**2. Markdown编辑器**
- 推荐: Typora / VS Code
- 用途: 润色文章

**3. 剪映/CapCut**
- 用途: 后期制作短视频
- 免费，功能强大

### 4.4 公众号文章Prompt模板

```markdown
# 智能体3A: 公众号文章改写师

你是公众号深度文章写手，擅长将专业分析改写成通俗易懂、引人入胜的文章。

## 输入
我会提供完整的产品深度分析 (app_case_file.md格式)

## 你的任务

将深度分析改写成3000-5000字的公众号文章，要求：

### 结构要求

```
标题: [产品名]凭什么[核心成就]? 深度拆解[核心机制]

开场 (300字):
- 用一个具体场景/痛点引入
- 抛出核心问题
- 承诺会讲清楚什么

正文 (2500-4000字):
第1部分: 它在替代谁? (500字)
- 传统方式的问题
- 新方式的本质差异
- 为什么现在能做到

第2部分: 为什么是这群用户? (800字)
- "没有男朋友的女孩子"策略
- 边缘用户的特征
- 如何从边缘包围主流

第3部分: 护城河在哪里? (800字)
- 表面看起来的壁垒
- 真正的壁垒
- 大厂为什么没做/做不好

第4部分: 如果你要做类似的 (800字)
- 3个改进方向
- 每个方向的具体打法
- 需要避免的坑

第5部分: 核心洞察 (300字)
- 提炼3-5个金句
- 可迁移的打法
- 对其他创业者的启发

结尾 (200字):
- 总结核心观点
- 引导关注/讨论
```

### 写作风格

**语言**:
- ✅ 通俗易懂 (初中生能看懂)
- ✅ 具体形象 (多用类比、例子)
- ✅ 有节奏感 (长短句结合)
- ❌ 专业术语 (LTV/CAC → 获客成本和用户价值)
- ❌ 空洞表述 ("产品很好""团队很强")

**举例**:
```
❌ 不好: "Perplexity采用RAG技术，提升了答案准确性"
✅ 好: "传统搜索给你10个链接让你自己找，Perplexity直接告诉你答案，还标注来自哪3个权威网站。就像你问路，别人不是给你10个地图App，而是直接说'左转50米'。"

❌ 不好: "其护城河在于数据飞轮"
✅ 好: "用的人越多，Perplexity就知道哪些问题容易被误解，从而优化答案。这就像一个老司机，开得越多越熟练。"
```

**结构**:
- 开场用故事/场景引入 (不要上来就讲产品)
- 每个部分都有小标题 (让读者快速扫读)
- 金句单独成段 (方便读者摘抄)
- 结尾要有行动号召 (讨论/关注/分享)

### 必须保留的内容

1. **核心数据** (融资/用户数/收入) - 保留并标注来源
2. **证据链** (重要断言要说明依据)
3. **对标分析** (至少提到2个对标对象)
4. **边缘用户策略** (这是核心洞察)
5. **3个可执行建议** (如果你要做类似的)

### 禁止

- ❌ 过度营销 (不要像软文)
- ❌ 标题党 (不要"震惊""秒杀"这类词)
- ❌ 删除关键信息 (为了通俗而删重要内容)

## 输出格式

直接输出Markdown格式的文章，包含：
- 标题
- 正文 (带小标题)
- 配图建议 (在相应位置标注 [配图: XXX])
```

### 4.5 短视频脚本Prompt模板

```markdown
# 智能体3B: 短视频脚本改写师

你是短视频脚本作者，擅长将深度分析浓缩成60秒/3分钟的视频脚本。

## 输入
完整的产品深度分析 + 公众号文章

## 你的任务

### 任务1: 60秒版本 (1个核心洞察)

**结构**:
```
[0-5秒] 开场 - 抓住注意力
画面: XXX
文案: "你有没有这种体验：[痛点场景]?"

[5-20秒] 痛点 - 放大问题
画面: XXX
文案: "[产品名]说：[解决方案一句话]"

[20-40秒] 核心洞察 - 讲清机制
画面: XXX
文案: "这就是[核心机制]，简单说就是[类比]"

[40-55秒] 金句 - 可复用打法
画面: XXX
文案: "[金句]"

[55-60秒] 结尾 - 行动号召
画面: XXX
文案: "想了解更多? 关注我，每周1个深度案例"
```

### 任务2: 3分钟版本 (3个核心洞察)

**结构**:
```
[0-20秒] 开场 + 痛点
[20-80秒] 洞察1: 它在替代谁
[80-140秒] 洞察2: 为什么是这群用户
[140-160秒] 洞察3: 如果你要做
[160-180秒] 结尾 + 关注
```

### 脚本要求

**画面**:
- 简单清晰 (PPT动画 or 真人出镜)
- 避免复杂图表
- 关键信息要有文字标注

**文案**:
- 口语化 (像聊天一样)
- 节奏快 (每句话≤10个字)
- 有停顿 (给观众思考时间)

**示例对比**:
```
❌ 不好: "Perplexity采用RAG技术，结合大语言模型的生成能力和搜索引擎的检索能力，为用户提供准确的答案"
✅ 好: "传统搜索 [停顿] / 给你10个链接 [停顿] / Perplexity直接给答案 [停顿] / 还告诉你来源 [停顿] / 这就是AI搜索"
```

## 输出格式

```markdown
# [产品名] - 60秒脚本

## 分镜表

| 时间 | 画面 | 文案 | 配音提示 |
|------|------|------|---------|
| 0-5s | Google搜索界面，点击多个链接 | "你是不是也这样：搜个问题，点开10个网页?" | 困惑语气 |
| 5-20s | Perplexity界面，直接显示答案 | "Perplexity说：我直接给答案，还标注来源" | 兴奋语气 |
| ... | ... | ... | ... |

## 配音稿 (完整)
[完整文案，供配音使用]

## 画面素材需求
- 需要录制: XXX
- 可以用PPT: XXX
- 需要找素材: XXX
```
```

### 4.6 自动化脚本

**scripts/agent3_rewriter.py**:

```python
#!/usr/bin/env python3
"""
智能体3: 内容改写师
将深度分析改写成多种内容形式
"""

import os
from anthropic import Anthropic

class ContentRewriter:
    def __init__(self, api_key):
        self.client = Anthropic(api_key=api_key)
        
        # 加载Prompt模板
        with open("prompts/agent3a_article.md", 'r') as f:
            self.article_prompt = f.read()
        
        with open("prompts/agent3b_video.md", 'r') as f:
            self.video_prompt = f.read()
    
    def rewrite_article(self, analysis_path):
        """改写成公众号文章"""
        # 读取深度分析
        with open(analysis_path, 'r') as f:
            analysis = f.read()
        
        # 调用Claude
        response = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=6000,
            system=self.article_prompt,
            messages=[
                {"role": "user", "content": f"请将以下深度分析改写成公众号文章:\n\n{analysis}"}
            ]
        )
        
        article = response.content[0].text
        
        # 保存
        product_name = analysis_path.split('/')[-1].replace('.md', '')
        output_path = f"articles/2026/{product_name}-深度拆解.md"
        
        with open(output_path, 'w') as f:
            f.write(article)
        
        print(f"文章已生成: {output_path}")
        return article
    
    def rewrite_video_script(self, analysis_path, version="60s"):
        """改写成短视频脚本"""
        # 读取深度分析
        with open(analysis_path, 'r') as f:
            analysis = f.read()
        
        # 调用Claude
        user_message = f"""
        请将以下深度分析改写成{version}短视频脚本:
        
        {analysis}
        """
        
        response = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=3000,
            system=self.video_prompt,
            messages=[
                {"role": "user", "content": user_message}
            ]
        )
        
        script = response.content[0].text
        
        # 保存
        product_name = analysis_path.split('/')[-1].replace('.md', '')
        output_path = f"scripts/2026/{product_name}-{version}.md"
        
        with open(output_path, 'w') as f:
            f.write(script)
        
        print(f"脚本已生成: {output_path}")
        return script
    
    def batch_rewrite(self, analysis_dir):
        """批量改写"""
        for filename in os.listdir(analysis_dir):
            if filename.endswith('.md'):
                analysis_path = os.path.join(analysis_dir, filename)
                
                # 生成文章
                self.rewrite_article(analysis_path)
                
                # 生成60秒脚本
                self.rewrite_video_script(analysis_path, "60s")
                
                # 生成3分钟脚本
                self.rewrite_video_script(analysis_path, "3min")

# 使用示例
if __name__ == "__main__":
    api_key = os.getenv("ANTHROPIC_API_KEY")
    rewriter = ContentRewriter(api_key)
    
    # 单个改写
    rewriter.rewrite_article("cases/2026/perplexity.md")
    rewriter.rewrite_video_script("cases/2026/perplexity.md", "60s")
    
    # 批量改写
    rewriter.batch_rewrite("cases/2026/")
```

---

## 五、完整工作流实例

### 5.1 Week 1 完整流程 (以Perplexity为例)

**Day 1: 信息收集 (30分钟)**

```bash
# 1. 运行智能体1
python scripts/agent1_collector.py collect "Perplexity"

# 2. 人工审核
# 打开 signals/watchlist.md
# 检查并补充信息
# 标注优先级: P0
```

**Day 2-3: 深度研究 (2小时)**

```bash
# 1. 实际使用产品 (30分钟)
# - 注册Perplexity账号
# - 试用各种查询
# - 记录"啊哈时刻"
# - 截图关键功能

# 2. 运行智能体2生成初稿
python scripts/agent2_analyzer.py analyze "Perplexity" \
    --intake-card signals/watchlist.md \
    --user-notes notes/perplexity-usage.md

# 3. 人工深度编辑 (1.5小时)
# 打开 cases/2026/perplexity.md
# - 补充个人洞察
# - 添加边缘用户分析
# - 完善对标分析
# - 检查证据账本
```

**Day 4: 改写文章 (1小时)**

```bash
# 1. 运行智能体3A
python scripts/agent3_rewriter.py article "cases/2026/perplexity.md"

# 2. 人工润色 (30分钟)
# 打开 articles/2026/perplexity-深度拆解.md
# - 调整开场
# - 补充类比和故事
# - 检查金句
# - 添加配图建议
```

**Day 5: 制作脚本 (30分钟)**

```bash
# 1. 运行智能体3B
python scripts/agent3_rewriter.py video "cases/2026/perplexity.md" --version 60s
python scripts/agent3_rewriter.py video "cases/2026/perplexity.md" --version 3min

# 2. 人工调整 (15分钟)
# - 检查节奏
# - 优化画面描述
```

**Day 6: 发布 (1小时)**

```
早上9:00: 发布公众号文章
下午: 录制视频 (用剪映/手机)
晚上8:00: 发布抖音/小红书
```

**Day 7: 复盘 (1小时)**

```
- 阅读量如何?
- 完读率如何?
- 评论有什么?
- 哪些内容受欢迎?
- 下次可以改进什么?
```

### 5.2 时间分配总结

| 阶段 | 时间 | 自动化程度 | 人工投入 |
|------|------|-----------|---------|
| 信息收集 | 30分钟 | 80% | 20% (审核) |
| 深度研究 | 2小时 | 50% | 50% (编辑) |
| 文章改写 | 1小时 | 70% | 30% (润色) |
| 脚本制作 | 30分钟 | 70% | 30% (调整) |
| 视频录制 | 1小时 | 0% | 100% |
| 发布推广 | 1小时 | 30% | 70% |
| **总计** | **6小时** | **50%** | **50%** |

**效率对比**:
- 纯人工: 需要12-15小时
- 智能体辅助: 6小时
- **节省时间**: 50-60%

---

## 六、工具选型总结

### 6.1 必备工具 ($40/月)

| 工具 | 用途 | 价格 | 优先级 |
|------|------|------|--------|
| Claude Pro | 深度分析 + 内容改写 | $20/月 | P0 |
| Perplexity Pro | 信息收集 | $20/月 | P0 |
| **小计** | | **$40/月** | |

### 6.2 推荐工具 (免费或低成本)

| 工具 | 用途 | 价格 |
|------|------|------|
| Notion | 笔记/协作 | 免费 (个人) |
| Typora | Markdown编辑 | $15 (买断) |
| OBS Studio | 录屏 | 免费 |
| 剪映 | 视频剪辑 | 免费 |
| VS Code | 代码/Markdown | 免费 |

### 6.3 可选工具 (进阶)

| 工具 | 用途 | 价格 | 说明 |
|------|------|------|------|
| Crunchbase Pro | 融资数据 | $29/月 | 100个案例后考虑 |
| SimilarWeb | 流量数据 | $125/月 | 500个案例后考虑 |
| Ahrefs | SEO数据 | $99/月 | 如果做SEO需要 |

**建议**:
- 前期: 只用Claude Pro + Perplexity Pro ($40/月)
- 100个案例后: 考虑Crunchbase Pro
- 500个案例后: 考虑流量分析工具

---

## 七、自动化程度规划

### 7.1 Phase 1: 手工为主 (案例1-100)

**目标**: 训练判断力，建立流程

**自动化程度**: 30%
- 智能体1: 信息收集 (80%自动)
- 智能体2: 生成初稿 (50%自动，但人工编辑占大头)
- 智能体3: 内容改写 (70%自动)

**人工投入**: 每个案例6小时

### 7.2 Phase 2: 半自动化 (案例100-500)

**目标**: 提高效率，保持质量

**自动化程度**: 60%
- 已有判断框架，编辑速度加快
- 可以批量处理

**人工投入**: 每个案例3小时

### 7.3 Phase 3: 高度自动化 (案例500+)

**目标**: 规模化生产

**自动化程度**: 80%
- 只做核心判断和质量把关

**人工投入**: 每个案例1.5小时

---

## 八、成本-收益分析

### 8.1 成本

**工具成本**:
- Claude Pro: $20/月 × 12 = $240/年
- Perplexity Pro: $20/月 × 12 = $240/年
- 其他工具: ~$100/年
- **总计**: ~$600/年

**时间成本** (前100个案例):
- 100个案例 × 6小时 = 600小时
- 按每周2个案例 = 50周 = 1年

### 8.2 收益

**无形收益** (核心):
1. **判断力**: 成为AI创业评估专家
2. **案例库**: 100个高质量案例 = 无法复制的资产
3. **个人品牌**: 100篇文章 + 100个视频 = 行业影响力
4. **人脉网络**: 创业者/投资人主动找你

**有形收益** (商业化):
1. **评估服务**: 
   - 免费评估吸引流量
   - 深度评估: ¥2999/次
   - 保守估计: 10单/年 = ¥30,000

2. **AI大赛**:
   - 政府采购: ¥50万/届
   - 第一年可能做1届

3. **咨询/培训**:
   - 企业培训: ¥10万/场
   - 第一年可能1-2场

**第一年收入预估**: ¥60-80万

**ROI**: ($600 + 600小时) → ¥60-80万

---

## 九、风险与应对

### 9.1 风险1: 内容同质化

**风险**: AI批量生产 → 缺少灵魂

**应对**:
- 人工编辑占50%精力 (前期)
- 必须亲自使用产品
- 补充个人洞察和独特观点

### 9.2 风险2: 时间不够

**风险**: 每周2个案例 = 12小时/周

**应对**:
- 降低频率: 每周1个 (质量>数量)
- 批量操作: 集中时间处理
- 提高效率: 用更多自动化

### 9.3 风险3: 数据不准确

**风险**: 信息来源不可靠 → 证据账本失效

**应对**:
- 严格证据分级 (A/B/C)
- 多源验证
- 标注"unknown"优于瞎编

---

## 十、总结

### 10.1 核心价值

这套系统的核心价值不是"批量生产内容"，而是：

1. **训练判断力**: 通过深度研究100+个AI产品，形成"模式识别"能力
2. **积累资产**: 案例库 = 无法复制的护城河
3. **建立品牌**: 持续输出 = 行业影响力
4. **商业闭环**: 内容→流量→评估→投资

### 10.2 成功关键

**不是工具，是思维**:
- ✅ 深度思考 > 批量生产
- ✅ 质量 > 数量
- ✅ 洞察 > 信息堆砌
- ✅ 长期主义 > 短期流量

**第一年目标**:
- 研究100个AI产品 (每周2个)
- 积累100个高质量案例
- 发布100篇文章 + 100个视频
- 建立"三湘问道"品牌

**12个月后**:
- 你是AI创业领域的专家
- 拥有100个案例的护城河
- 有稳定的评估服务收入
- 有机会做AI大赛/投资

---

**版本**: v1.0  
**下一步**: 开始Week 1 完整流程测试
